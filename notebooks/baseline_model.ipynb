{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from collections import Counter\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "# Define All Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def get_data(filename):\n",
    "    \"\"\"Fungsi untuk melakukan load data pada file .tsv maupun .txt\n",
    "    \n",
    "    File yang digunakan yaitu file .tsv maupun file yang mampu dibuka\n",
    "    menggunakan teks editor. Dalam file tersebut terdapat tag pembuka <kalimat>\n",
    "    dan diakhiri tag penutup </kalimat> yang berfungsi sebagai penanda bahwa\n",
    "    entitas tersebut termasuk ke dalam satu kalimat.\n",
    "    \n",
    "    Args:\n",
    "        filename: string dari nama file yang akan diload datanya.\n",
    "        \n",
    "    Return:\n",
    "        list dari kata-kata dan tags dengan index yang menunjukkan posisi kalimat tersebut.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load data dan buka sebagai file\n",
    "    sentences = []\n",
    "    tags = []\n",
    "    with open(filename) as file:\n",
    "        contents = file.readlines()\n",
    "\n",
    "    # Hapus karakter \\n yang tidak dibutuhkan\n",
    "    contents = [content.strip() for content in contents]\n",
    "    idx = 0\n",
    "    while idx < len(contents):\n",
    "        word = []\n",
    "        tag = []\n",
    "        # looping sampai menemukan pattern dengan awalan </kalimat\n",
    "        while not contents[idx].startswith('</kalimat'):\n",
    "            # kondisi jika menemukan sebuah data yang tidak memiliki awalan <kalimat\n",
    "            if not contents[idx].startswith('<kalimat'):\n",
    "                temp_word, temp_tag = contents[idx].split(\"\\t\")\n",
    "                word.append(temp_word.lower())\n",
    "                tag.append(temp_tag)\n",
    "            idx += 1\n",
    "        sentences.append(word)\n",
    "        tags.append(tag)\n",
    "        idx += 2\n",
    "        \n",
    "    return sentences, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(multi_list):\n",
    "    \"\"\"Mengembalikan list multi dimensi ke dalam list satu dimensi.\n",
    "    \n",
    "    Input list yang masuk di proses menggunakan method from_iterable dari\n",
    "    package itertools dan mengembalikan object berupa generator yang iterable.\n",
    "    \n",
    "    Args:\n",
    "        multi_list: list multi dimensi.\n",
    "    \n",
    "    Return:\n",
    "        list satu dimensi yang nantinya digunakan untuk pemrosesan lebih lanjut.\n",
    "    \"\"\"\n",
    "    \n",
    "    return chain.from_iterable(multi_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emission_table(words, tags):\n",
    "    \"\"\"Membuat tabel emisi dari input kata dan tags.\n",
    "    \n",
    "    Fungsi untuk mengembalikan sebuah tabel dari kata dan kemunculan tags terhadap kata tersebut.\n",
    "    \n",
    "    Args:\n",
    "        words: list kata.\n",
    "        tags: list tags.\n",
    "    \n",
    "    Return:\n",
    "        dictionary yang merepresntasikan tabel emisi.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Membuat representasi tabel emission probability dari HMM\n",
    "    hidden_state = {}\n",
    "    for word in words:\n",
    "        # Jika word belum pernah ditemui maka akan digenerate\n",
    "        # tagset berserta probabilitasnya\n",
    "        if word not in hidden_state.keys():\n",
    "            word_tags = []\n",
    "            for idx, wrd in enumerate(words):\n",
    "                if wrd == word :\n",
    "                    word_tags.append(tags[idx])\n",
    "            # Membuat dictionary berisi semua tagset dari sebuah word\n",
    "            # pada korpus. Berserta jumlah kemunculan setiap tagsetnya\n",
    "            tag_count = {}\n",
    "            for tag in word_tags:\n",
    "                if tag not in tag_count.keys():\n",
    "                    tag_count[tag] = 1\n",
    "                else:\n",
    "                    tag_count[tag] += 1\n",
    "            total = 0\n",
    "            # Mengubah jumlah kemunculan menjadi probabilitas\n",
    "            tag_prob = {}\n",
    "            for count in tag_count.values():\n",
    "                total += count\n",
    "            for tagset in tag_count.keys():\n",
    "                tag_prob[tagset] = tag_count[tagset]/total\n",
    "            hidden_state[word] = tag_prob\n",
    "        else:\n",
    "            # Jika word sudah pernah ditemui maka akan dilewati\n",
    "            continue\n",
    "    return(hidden_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Separate Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dan pisahkan dataset sebanyak 1000 data train dan 20 data test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../data/corpus.tsv'\n",
    "sentences, tags = get_data(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mengambil 1020 data awal\n",
    "data_train, data_test, tags_train, tags_test = sentences[:1000], sentences[1000:1020], tags[:1000], tags[1000:1020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = list(flatten(data_train))\n",
    "tags_train = list(flatten(tags_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabel emisi dibuat berdasarkan data train yang telah diambil pada corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_table = get_emission_table(data_train, tags_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def predict_common_tag(data, emmision_table):\n",
    "    \"\"\"Fungsi untuk memprediksi suatu tag dengan pendekatan baseline.\n",
    "    \n",
    "    Pendekatan baseline memungkinkan prediksi suatu tag dengan menghitung kemunculan suatu tag\n",
    "    dalam corpus.\n",
    "    \n",
    "    Args:\n",
    "        data: list berisi kata yang akan diprediksi.\n",
    "        emmision_table: dictionary berisi tabel emisi\n",
    "    \n",
    "    Return:\n",
    "        prediksi tags dari list data input\n",
    "    \"\"\"\n",
    "    \n",
    "    # dengan menggunakan hidden table untuk membangun baseline model berdasarkan corpus\n",
    "    predict_tags = []\n",
    "    for word in data:\n",
    "        if word not in emmision_table.keys():\n",
    "            predict_tags.append('NN')\n",
    "        else:\n",
    "            most_common_tag = max(emmision_table[word].items(), key=operator.itemgetter(1))[0]\n",
    "            predict_tags.append(most_common_tag)\n",
    "    \n",
    "    return predict_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_baseline(predict_list, test_list):\n",
    "    \"\"\"Fungsi untuk menghitung akurasi dari model baseline\n",
    "    \n",
    "    Hasil prediksi dari model baseline dibandingkan dengan data test yang berisi \n",
    "    tags sesungguhnya.\n",
    "    \n",
    "    Args:\n",
    "        predict_list: list dari prediksi menggunakan baseline\n",
    "        test_list: list berisi tags yang digunakan untuk validasi model\n",
    "    \n",
    "    Return:\n",
    "        Mengembalikan nilai akurasi dari model yang dibangun\n",
    "    \n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for i in range(len(predict_list)):\n",
    "        if (predict_list[i] == test_list[i]):\n",
    "            count += 1\n",
    "    \n",
    "    accuracy = count / len(test_list)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hitung akurasi berdasarkan data test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = []\n",
    "for sentence in data_test:\n",
    "    predict_tags = predict_common_tag(sentence, hidden_table)\n",
    "    predict.append(predict_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_tags_test = list(flatten(tags_test))\n",
    "flatten_predict = list(flatten(predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi model baseline : 0.8544117647058823\n"
     ]
    }
   ],
   "source": [
    "akurasi = get_accuracy_baseline(flatten_predict, flatten_tags_test)\n",
    "print(\"Akurasi model baseline :\",akurasi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output hasil prediksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kalimat: fitch ratings , dalam siaran pers -nya , senin , mengatakan bahwa prospek rating kedua bank itu tetap di stabil .\n",
      "Prediksi: NNP NNP Z IN NN PRP Z NNP Z VB SC NN FW CD NNP PR RB IN JJ Z\n"
     ]
    }
   ],
   "source": [
    "print(\"Kalimat:\", ' '.join(data_test[6]))\n",
    "print(\"Prediksi:\", ' '.join(predict[6]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
