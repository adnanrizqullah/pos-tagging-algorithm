{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(multi_list):\n",
    "    \"\"\"Mengembalikan list multi dimensi ke dalam list satu dimensi.\n",
    "    \n",
    "    Input list yang masuk di proses menggunakan method from_iterable dari\n",
    "    package itertools dan mengembalikan object berupa generator yang iterable.\n",
    "    \n",
    "    Args:\n",
    "        multi_list: list multi dimensi.\n",
    "    \n",
    "    Return:\n",
    "        list satu dimensi yang nantinya digunakan untuk pemrosesan lebih lanjut.\n",
    "    \"\"\"\n",
    "    \n",
    "    return chain.from_iterable(multi_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filename):\n",
    "    \"\"\"Fungsi untuk melakukan load data pada file .tsv maupun .txt\n",
    "    \n",
    "    File yang digunakan yaitu file .tsv maupun file yang mampu dibuka\n",
    "    menggunakan teks editor. Dalam file tersebut terdapat tag pembuka <kalimat>\n",
    "    dan diakhiri tag penutup </kalimat> yang berfungsi sebagai penanda bahwa\n",
    "    entitas tersebut termasuk ke dalam satu kalimat.\n",
    "    \n",
    "    Args:\n",
    "        filename: string dari nama file yang akan diload datanya.\n",
    "        \n",
    "    Return:\n",
    "        list dari kata-kata dan tags dengan index yang menunjukkan posisi kalimat tersebut.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load data dan buka sebagai file\n",
    "    sentences = []\n",
    "    tags = []\n",
    "    with open(filename) as file:\n",
    "        contents = file.readlines()\n",
    "\n",
    "    # Hapus karakter \\n yang tidak dibutuhkan\n",
    "    contents = [content.strip() for content in contents]\n",
    "    idx = 0\n",
    "    while idx < len(contents):\n",
    "        word = []\n",
    "        tag = []\n",
    "        # looping sampai menemukan pattern dengan awalan </kalimat\n",
    "        while not contents[idx].startswith('</kalimat'):\n",
    "            # kondisi jika menemukan sebuah data yang tidak memiliki awalan <kalimat\n",
    "            if not contents[idx].startswith('<kalimat'):\n",
    "                temp_word, temp_tag = contents[idx].split(\"\\t\")\n",
    "                word.append(temp_word.lower())\n",
    "                tag.append(temp_tag)\n",
    "            idx += 1\n",
    "        sentences.append(word)\n",
    "        tags.append(tag)\n",
    "        idx += 2\n",
    "        \n",
    "    return sentences, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/\"\n",
    "file_name = \"Indonesian_Manually_Tagged_Corpus_ID.tsv\"\n",
    "words, tags = get_data(file_path + file_name)\n",
    "words = list(flatten(words))[:1000]\n",
    "tags = list(flatten(tags))[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emission_table(words, tags):\n",
    "# Membuat representasi tabel emission probability dari HMM\n",
    "    hidden_state = {}\n",
    "    for word in words:\n",
    "        # Jika word belum pernah ditemui maka akan digenerate\n",
    "        # tagset berserta probabilitasnya\n",
    "        if word not in hidden_state.keys():\n",
    "            word_tags = []\n",
    "            for idx, wrd in enumerate(words):\n",
    "                if wrd == word :\n",
    "                    word_tags.append(tags[idx])\n",
    "            # Membuat dictionary berisi semua tagset dari sebauh word\n",
    "            # pada korpus. Berserta jumlah kemunculan setiap tagsetnya\n",
    "            tag_count = {}\n",
    "            for tag in word_tags:\n",
    "                if tag not in tag_count.keys():\n",
    "                    tag_count[tag] = 1\n",
    "                else:\n",
    "                    tag_count[tag] += 1\n",
    "            total = 0\n",
    "            # Mengubah jumlah kemunculan menjadi probabilitas\n",
    "            tag_prob = {}\n",
    "            for count in tag_count.values():\n",
    "                total += count\n",
    "            for tagset in tag_count.keys():\n",
    "                tag_prob[tagset] = tag_count[tagset]/total\n",
    "            hidden_state[word] = tag_prob\n",
    "        else:\n",
    "            # Jika word sudah pernah ditemui maka akan dilewati\n",
    "            continue\n",
    "    return(hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = get_emission_table(words, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "484"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hidden)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
